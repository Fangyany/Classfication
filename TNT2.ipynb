{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5438/4039670680.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lanegcn/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lanegcn/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lanegcn/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lanegcn/lib/python3.7/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lanegcn/lib/python3.7/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GraghGAN/data.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m'preprocess'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preprocess'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from fractions import gcd\n",
    "from numbers import Number\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from data import ArgoDataset, collate_fn\n",
    "from utils import gpu, to_long,  Optimizer, StepLR\n",
    "\n",
    "from layers import Conv1d, Res1d, Linear, LinearRes, Null\n",
    "from numpy import float64, ndarray\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "\n",
    "from lanegcn import PredNet, get_model\n",
    "import torch\n",
    "from torch.utils.data import Sampler, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "config, Dataset, collate_fn, net, loss, post_process, opt = get_model()\n",
    "import os\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import shutil\n",
    "from importlib import import_module\n",
    "from numbers import Number\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Sampler, DataLoader\n",
    "\n",
    "\n",
    "from utils import Logger, load_pretrain\n",
    "def worker_init_fn(pid):\n",
    "    np_seed = int(pid)\n",
    "    np.random.seed(np_seed)\n",
    "    random_seed = np.random.randint(2 ** 32 - 1)\n",
    "    random.seed(random_seed)\n",
    "\n",
    "\n",
    "dataset = Dataset(config[\"train_split\"], config, train=True)\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    num_workers=config[\"workers\"],\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    worker_init_fn=worker_init_fn,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "\n",
    "for i, data in enumerate(train_loader):\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lanegcn import ActorNet, MapNet, actor_gather, graph_gather\n",
    "actor_net = ActorNet(config)\n",
    "map_net = MapNet(config)\n",
    "\n",
    "# construct actor feature\n",
    "actors, actor_idcs = actor_gather(gpu(data[\"feats\"]))\n",
    "actor_ctrs = gpu(data[\"ctrs\"])\n",
    "actors = actor_net(actors)\n",
    "\n",
    "# construct map features\n",
    "graph = graph_gather(to_long(gpu(data[\"graph\"])))\n",
    "nodes, node_idcs, node_ctrs = map_net(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TNT_fun import Classifier\n",
    "\n",
    "goda_classifier = Classifier(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33084, 128]) torch.Size([33084])\n"
     ]
    }
   ],
   "source": [
    "goda_cls = goda_classifier(nodes)\n",
    "print(nodes.size(), goda_cls.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "batch_size = len(graph['ctrs'])\n",
    "print(len(graph['ctrs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_GODA_NUM = 200\n",
    "goda_score = []\n",
    "goda_coord = []\n",
    "goda_feat = []\n",
    "for i in range(batch_size):\n",
    "    scores = goda_cls[graph['idcs'][i]]\n",
    "    _, idcs = torch.sort(scores, descending=True)\n",
    "    assert len(idcs) > DEFAULT_GODA_NUM, 'Invalid goda number'\n",
    "\n",
    "    idcs = idcs[:DEFAULT_GODA_NUM]\n",
    "    goda_score.append(scores[idcs])\n",
    "    goda_coord.append(graph['ctrs'][i][idcs])\n",
    "    goda_feat.append(nodes[graph['idcs'][i]][idcs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 torch.Size([200]) torch.Size([200, 2]) torch.Size([200, 128])\n"
     ]
    }
   ],
   "source": [
    "print(len(goda_score), goda_score[0].size(), goda_coord[0].size(), goda_feat[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "goda_score = torch.stack(goda_score, dim=0)\n",
    "goda_coord = torch.stack(goda_coord, dim=0)\n",
    "goda_feat = torch.stack(goda_feat, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 200])\n"
     ]
    }
   ],
   "source": [
    "print(goda_score.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TNT_fun import GoalGenerator\n",
    "\n",
    "goal_generator = GoalGenerator(config, n_blk=2)\n",
    "\n",
    "\n",
    "goal_pred = goal_generator(goda_score, goda_coord, goda_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6, 2])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_pred.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "print(len(data['ctrs']), data['ctrs'][0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "GT = []\n",
    "for i in range(len(data['ctrs'])):\n",
    "    GT.append(data['ctrs'][0])\n",
    "\n",
    "# goal_gt = torch.cat(GT, dim=1).permute(1,0,2)\n",
    "# print(goal_gt.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TNT_fun import TrajCompletor\n",
    "\n",
    "traj_completor = TrajCompletor(config)\n",
    "goal_gt = data['ctrs']\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "goal_mock = torch.stack(GT)\n",
    "print(goal_mock.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_idcs = torch.LongTensor([idcs[0] for idcs in actor_idcs])\n",
    "agent_feat = actors[agent_idcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_pred = traj_completor(agent_feat, goal_mock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_pred = torch.ones(traj_pred.shape[0], traj_pred.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6, 30, 5])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_pred = torch.ones(traj_pred.shape[0], traj_pred.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_pred.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IF Train = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph_da' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14519/235214323.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_scatter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscatter_add\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_da\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ms_edges'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgoda_cls_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoda_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgoda_cls_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgoda_cls_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'u'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'v'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgoda_cls_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'graph_da' is not defined"
     ]
    }
   ],
   "source": [
    "from torch_scatter import scatter_add\n",
    "edges = graph_da['ms_edges'][0]\n",
    "goda_cls_tmp = goda_cls.clone()\n",
    "goda_cls_tmp = scatter_add(goda_cls_tmp.index_select(0, edges['u']), edges['v'], out=goda_cls_tmp, dim=0)\n",
    "\n",
    "traj_pred = traj_completor(agent_feat, goal_pred)\n",
    "traj_pred[:, :, -1, 0:2] = goal_pred\n",
    "\n",
    "# score_pred = torch.ones(traj_pred.shape[0], traj_pred.shape[1])  # uniform distribution\n",
    "# ~ score from heatmap\n",
    "score_pred = []\n",
    "for b in range(batch_size):\n",
    "    goals = graph['ctrs'][b]\n",
    "    goal_scores = goda_cls_tmp[graph['idcs'][b]]\n",
    "    score_tmp = []\n",
    "    for g in goal_pred[b]:\n",
    "        dist = torch.sqrt(torch.sum((goals - g.unsqueeze(0))**2, dim=1))\n",
    "        min_idx = torch.argmin(dist)\n",
    "        score_tmp.append(goal_scores[min_idx])\n",
    "    score_pred.append(score_tmp)\n",
    "score_pred = torch.Tensor(score_pred).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 4, 8])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors = np.array([2**s for s in range(4)], dtype=np.int)\n",
    "factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.path import Path\n",
    "from shapely.geometry import LineString, Point, Polygon, MultiPolygon\n",
    "from shapely.ops import cascaded_union, nearest_points, unary_union\n",
    "from argoverse.map_representation.map_api import ArgoverseMap\n",
    "\n",
    "MAP_RADIUS = 100.0\n",
    "DA_RESOLUTION = 1.0\n",
    "DA_NUM_SCALES = 4\n",
    "am = ArgoverseMap()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def construct_freespace_layer(city_name, orig, rot, lane_ids):\n",
    "        # ~ Sample according to freespace\n",
    "        x_min = np.floor(orig[0] - MAP_RADIUS)\n",
    "        x_max = np.floor(orig[0] + MAP_RADIUS)\n",
    "        y_min = np.floor(orig[1] - MAP_RADIUS)\n",
    "        y_max = np.floor(orig[1] + MAP_RADIUS)\n",
    "\n",
    "        x, y = np.meshgrid(np.arange(x_min, x_max, DA_RESOLUTION), np.arange(y_min, y_max, DA_RESOLUTION))\n",
    "        pts = np.stack((x.flatten(), y.flatten()), axis=1)\n",
    "\n",
    "        # Driveable area\n",
    "        idcs_da = am.get_raster_layer_points_boolean(pts, city_name, 'driveable_area')  # np.ndarray, Boolean\n",
    "\n",
    "        # lane ROI\n",
    "        lane_polygon = unary_union([\n",
    "            Polygon(am.get_lane_segment_polygon(lane, city_name)).buffer(0.1)\n",
    "            for lane in lane_ids])\n",
    "        if isinstance(lane_polygon, MultiPolygon):\n",
    "            polygons = list(lane_polygon)\n",
    "            for polygon in polygons:\n",
    "                # select the polygon contains the target\n",
    "                if polygon.contains(Point(orig)):\n",
    "                    lane_polygon = polygon\n",
    "        lane_polygon = lane_polygon.buffer(15.0)\n",
    "\n",
    "        poly = Path(np.array(lane_polygon.exterior.coords.xy).T)\n",
    "        idcs_roi = poly.contains_points(pts)\n",
    "\n",
    "        idcs_da = np.logical_and(idcs_da, idcs_roi)\n",
    "        pts_da = pts[idcs_da]\n",
    "\n",
    "        # ~ get graph topology\n",
    "        ids = np.full(len(pts), -1)\n",
    "        npts_da = np.count_nonzero(idcs_da)\n",
    "        ids[idcs_da] = np.arange(npts_da)\n",
    "        ids = ids.reshape(x.shape)\n",
    "\n",
    "        ms_edges = dict()\n",
    "        factors = np.array([2**s for s in range(DA_NUM_SCALES)], dtype=np.int)\n",
    "        for F in factors:\n",
    "            ids_us = []  # up\n",
    "            ids_ls = []  # left\n",
    "            ids_uls = []  # upper-left\n",
    "            ids_urs = []  # upper-right\n",
    "            for K in range(1, F + 1):\n",
    "                pad_n = np.ones((2, 2), dtype=np.int) * K\n",
    "                ids_padded = np.pad(ids, pad_n, constant_values=-1, mode='constant')\n",
    "\n",
    "                # ! Only get a half of the edges due to memory issue\n",
    "                # ! The other part can be retrieved by the symmetry\n",
    "                ids_u = ids_padded[:-K*2, K:-K].flatten()\n",
    "                ids_us.append(ids_u)\n",
    "\n",
    "                ids_l = ids_padded[K:-K, :-K*2].flatten()\n",
    "                ids_ls.append(ids_l)\n",
    "\n",
    "                ids_ul = ids_padded[:-K*2, :-K*2].flatten()\n",
    "                ids_uls.append(ids_ul)\n",
    "\n",
    "                ids_ur = ids_padded[:-K*2, K*2:].flatten()\n",
    "                ids_urs.append(ids_ur)\n",
    "\n",
    "            ids_us = np.array(ids_us)\n",
    "            ids_ls = np.array(ids_ls)\n",
    "            ids_uls = np.array(ids_uls)\n",
    "            ids_urs = np.array(ids_urs)\n",
    "\n",
    "            d = F - 1\n",
    "            if d == 0:\n",
    "                ids_tgts = [ids_us[-1], ids_ls[-1], ids_uls[-1], ids_urs[-1]]\n",
    "            else:\n",
    "                ids_tgts = []\n",
    "                for ids_tar in [ids_us, ids_ls, ids_uls, ids_urs]:\n",
    "                    ids_d = ids_tar[:d]\n",
    "                    ids_fin = ids_tar[d]\n",
    "                    ids_fin[np.any(ids_d == -1, axis=0)] = -1\n",
    "                    ids_tgts.append(ids_fin)\n",
    "\n",
    "            edges_dirs = []\n",
    "            # ! Self-loop is not saved due to memory issue\n",
    "            # edges_dirs += [np.tile(np.arange(npts_da), (2, 1)).transpose()]  # self loop\n",
    "            for ids_tgt in ids_tgts:\n",
    "                edges = np.stack((ids_tgt[idcs_da], np.arange(npts_da)), axis=1)\n",
    "                edges = edges[edges[:, 0] >= 0]\n",
    "                edges_dirs.append(edges)\n",
    "            edges_dirs = np.concatenate(edges_dirs).astype(np.int16)\n",
    "\n",
    "            edges = dict()\n",
    "            edges['u'] = edges_dirs[:, 0]\n",
    "            edges['v'] = edges_dirs[:, 1]\n",
    "            ms_edges[F] = edges\n",
    "            # print('new - level: {}, num: {}'.format(F, ms_edges[F]['u'].shape))\n",
    "\n",
    "        pts_da[:, 0:2] = (pts_da[:, 0:2] - orig).dot(rot)\n",
    "\n",
    "        graph = dict()\n",
    "        graph['num_nodes'] = len(pts_da)\n",
    "        graph['ctrs'] = pts_da.astype(np.float32)\n",
    "        graph['ms_edges'] = ms_edges\n",
    "        return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max, y_min, y_max = config['pred_range']\n",
    "radius = max(abs(x_min), abs(x_max)) + max(abs(y_min), abs(y_max))\n",
    "lane_ids = am.get_lane_ids_in_xy_bbox(data['orig'][0][0], data['orig'][0][1], data['city'][0], radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "rsub() received an invalid combination of arguments - got (Tensor, numpy.ndarray), but expected one of:\n * (Tensor input, Tensor other, *, Number alpha)\n * (Tensor input, Number other, Number alpha)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14519/2681075982.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mconstruct_freespace_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'city'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'orig'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rot'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlane_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_14519/331818100.py\u001b[0m in \u001b[0;36mconstruct_freespace_layer\u001b[0;34m(city_name, orig, rot, lane_ids)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;31m# print('new - level: {}, num: {}'.format(F, ms_edges[F]['u'].shape))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mpts_da\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpts_da\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lanegcn/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__rsub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rsub__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rdiv__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: rsub() received an invalid combination of arguments - got (Tensor, numpy.ndarray), but expected one of:\n * (Tensor input, Tensor other, *, Number alpha)\n * (Tensor input, Number other, Number alpha)\n"
     ]
    }
   ],
   "source": [
    "a =  construct_freespace_layer(data['city'][0], data['orig'][0], data['rot'][0], lane_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('lanegcn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07e1035589aed84bd7169a62ca865480aa9cea1eaec18b5fbc2b7aab1975a44f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
